{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import model_selection # <---- PARTICIONADO\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "La función a continuación levanta todos los datos en la carpeta indicada (ej. \"clases/\") y los almacena en un diccionario, donde las claves corresponden a la clase en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_csv_files(folder, Nfeatures=102):\n",
    "    '''\n",
    "    Load all the \"CSV\" files in a folder, and store each one in a dictionary.\n",
    "    '''\n",
    "    \n",
    "    #filenames = glob.glob(rel_path + '*.csv')\n",
    "    \n",
    "    clase = dict()\n",
    "    \n",
    "    for n in range(0,24):\n",
    "        \n",
    "      clase[n] = pandas.read_csv(folder +'clase' + str(n) + '.csv', sep=',',header=None, names=['f'+str(m) for m in range(0,Nfeatures)])\n",
    "#        clase[n+1] = np.array(pandas.read_csv(folder +'clase' + str(n+1) + '.csv', sep=',',header=None, names=['f'+str(m) for m in range(0,Nfeatures)]))\n",
    "    return clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Levanto los datos de los cromosomas almacenados en la carpeta \"clases/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f0   f1     f2     f3     f4     f5     f6     f7     f8     f9  \\\n",
      "0     1954  148  254.0  232.0  224.0  187.0  175.0  167.0  165.0  167.0   \n",
      "1     1621  134  202.0  191.0  179.0  169.0  144.0  132.0  123.0  120.0   \n",
      "2     1841  115  233.0  213.0  196.0  177.0  164.0  149.0  141.0  138.0   \n",
      "3     1784  106  197.0  201.0  180.0  173.0  164.0  157.0  152.0  150.0   \n",
      "4     2663  155  235.0  223.0  213.0  197.0  184.0  167.0  157.0  167.0   \n",
      "5     1640  148  233.0  224.0  215.0  205.0  176.0  163.0  164.0  169.0   \n",
      "6     1470  140  241.0  212.0  204.0  187.0  162.0  151.0  155.0  156.0   \n",
      "7     2430  150  207.0  207.0  179.0  156.0  153.0  151.0  157.0  160.0   \n",
      "8     1935  115  217.0  192.0  177.0  171.0  166.0  165.0  164.0  167.0   \n",
      "9     1318  115  205.0  196.0  177.0  164.0  161.0  156.0  156.0  159.0   \n",
      "10    1775  118  242.0  225.0  217.0  204.0  196.0  186.0  184.0  180.0   \n",
      "11    1348  114  202.0  176.0  166.0  163.0  160.0  156.0  153.0  158.0   \n",
      "12    1305  109  206.0  206.0  174.0  164.0  156.0  157.0  154.0  153.0   \n",
      "13    1175  104  203.0  180.0  168.0  160.0  149.0  141.0  149.0  147.0   \n",
      "14    1616  126  218.0  218.0  195.0  178.0  159.0  168.0  176.0  181.0   \n",
      "15    1626  131  205.0  193.0  179.0  163.0  144.0  112.0  102.0   95.0   \n",
      "16    1471  144  224.0  209.0  198.0  179.0  159.0  156.0  159.0  162.0   \n",
      "17    1560  127  232.0  210.0  191.0  181.0  181.0  179.0  180.0  180.0   \n",
      "18    3120  139  220.0  203.0  194.0  180.0  174.0  181.0  183.0  172.0   \n",
      "19    1166  116  189.0  189.0  165.0  161.0  169.0  172.0  174.0  180.0   \n",
      "20    2198  133  232.0  223.0  218.0  245.0  237.0  207.0  194.0  175.0   \n",
      "21    2140  129  235.0  213.0  188.0  166.0  159.0  152.0  166.0  170.0   \n",
      "22    1894  118  198.0  186.0  180.0  171.0  169.0  166.0  170.0  171.0   \n",
      "23    1586  127  196.0  196.0  178.0  165.0  169.0  155.0  145.0  138.0   \n",
      "24    1120   97  199.0  175.0  175.0  160.0  153.0  153.0  152.0  151.0   \n",
      "25    1204  114  206.0  188.0  147.0  140.0  128.0  125.0  123.0  122.0   \n",
      "26    2034  120  226.0  205.0  191.0  181.0  172.0  168.0  166.0  164.0   \n",
      "27    1314  121  211.0  203.0  184.0  173.0  161.0  158.0  152.0  150.0   \n",
      "28    1285  115  201.0  180.0  161.0  154.0  154.0  148.0  143.0  137.0   \n",
      "29    2458  125  230.0  210.0  202.0  188.0  173.0  157.0  158.0  156.0   \n",
      "...    ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "1106  2547  147  166.0  144.0  142.0  141.0  165.0  173.0  167.0  176.0   \n",
      "1107  2298  134  239.0  229.0  207.0  187.0  168.0  161.0  162.0  171.0   \n",
      "1108  1518  122  202.0  184.0  171.0  169.0  166.0  162.0  160.0  155.0   \n",
      "1109  1446  127  205.0  198.0  189.0  176.0  169.0  149.0  147.0  145.0   \n",
      "1110  2404  109  237.0  237.0  207.0  196.0  192.0  182.0  175.0  168.0   \n",
      "1111  2187  105  228.0  219.0  190.0  174.0  174.0  165.0  159.0  155.0   \n",
      "1112  1492  104  208.0  186.0  181.0  170.0  163.0  164.0  157.0  158.0   \n",
      "1113  1527  108  214.0  200.0  184.0  172.0  162.0  157.0  155.0  156.0   \n",
      "1114  2209  140  214.0  202.0  190.0  184.0  188.0  187.0  188.0  187.0   \n",
      "1115  1924  210  228.0  228.0  195.0  176.0  179.0  179.0  173.0  176.0   \n",
      "1116  3193  158  248.0  235.0  221.0  195.0  184.0  170.0  172.0  165.0   \n",
      "1117  2545  163  221.0  215.0  205.0  191.0  192.0  193.0  192.0  189.0   \n",
      "1118  1185  103  225.0  217.0  192.0  178.0  173.0  163.0  165.0  167.0   \n",
      "1119  1225   95  201.0  182.0  182.0  167.0  172.0  172.0  164.0  159.0   \n",
      "1120  1929  120  238.0  223.0  220.0  207.0  195.0  184.0  172.0  174.0   \n",
      "1121  1345  124  231.0  214.0  202.0  195.0  191.0  186.0  184.0  185.0   \n",
      "1122  1835  119  217.0  217.0  180.0  171.0  162.0  158.0  151.0  152.0   \n",
      "1123  2219  120  202.0  195.0  186.0  176.0  172.0  166.0  161.0  164.0   \n",
      "1124  1206  101  217.0  213.0  200.0  191.0  181.0  173.0  171.0  169.0   \n",
      "1125  1296  110  187.0  172.0  174.0  171.0  178.0  181.0  182.0  180.0   \n",
      "1126  1982  106  231.0  254.0  209.0  175.0  162.0  157.0  152.0  148.0   \n",
      "1127  1640  110  221.0  193.0  184.0  176.0  185.0  189.0  185.0  174.0   \n",
      "1128  1567  110  220.0  201.0  196.0  181.0  161.0  166.0  157.0  152.0   \n",
      "1129  1200  109  210.0  210.0  184.0  165.0  149.0  149.0  153.0  163.0   \n",
      "1130  1528  117  198.0  191.0  188.0  186.0  204.0  192.0  184.0  182.0   \n",
      "1131  2053  112  226.0  226.0  195.0  169.0  152.0  141.0  136.0  131.0   \n",
      "1132  3221  138  241.0  226.0  213.0  199.0  177.0  171.0  167.0  167.0   \n",
      "1133  1905  138  222.0  207.0  198.0  194.0  180.0  178.0  180.0  175.0   \n",
      "1134  2079  139  223.0  199.0  189.0  179.0  172.0  177.0  176.0  164.0   \n",
      "1135  3242  154  244.0  227.0  209.0  185.0  185.0  180.0  190.0  189.0   \n",
      "\n",
      "      ...      f92    f93    f94    f95    f96    f97    f98    f99   f100  \\\n",
      "0     ...    113.0  127.0  150.0  149.0  142.0  134.0  129.0  141.0  164.0   \n",
      "1     ...    127.0  129.0  138.0  129.0  118.0  102.0  105.0  129.0  200.0   \n",
      "2     ...    141.0  151.0  153.0  152.0  156.0  155.0  155.0  160.0  167.0   \n",
      "3     ...    118.0  126.0  138.0  138.0  138.0  130.0  129.0  149.0  150.0   \n",
      "4     ...    154.0  173.0  174.0  165.0  154.0  141.0  151.0  177.0  201.0   \n",
      "5     ...    153.0  164.0  160.0  161.0  146.0  149.0  146.0  138.0  145.0   \n",
      "6     ...    172.0  176.0  176.0  170.0  161.0  156.0  158.0  169.0  194.0   \n",
      "7     ...     97.0  115.0  126.0  151.0  151.0  137.0  124.0  121.0  133.0   \n",
      "8     ...    168.0  162.0  156.0  150.0  142.0  166.0  231.0  147.0  242.0   \n",
      "9     ...    127.0  143.0  147.0  148.0  143.0  139.0  128.0  128.0  130.0   \n",
      "10    ...    146.0  153.0  150.0  148.0  142.0  136.0  132.0  136.0  136.0   \n",
      "11    ...    124.0  149.0  145.0  123.0  132.0  135.0  151.0  162.0  155.0   \n",
      "12    ...    131.0  141.0  139.0  138.0  137.0  138.0  137.0  134.0  143.0   \n",
      "13    ...    111.0  112.0  117.0  123.0  110.0  115.0  115.0  111.0  129.0   \n",
      "14    ...    138.0  157.0  163.0  171.0  154.0  142.0  126.0  123.0  144.0   \n",
      "15    ...    118.0  165.0  175.0  180.0  168.0  154.0  146.0  146.0  154.0   \n",
      "16    ...    101.0  114.0  146.0  151.0  149.0  141.0  127.0  129.0  148.0   \n",
      "17    ...    140.0  153.0  154.0  154.0  148.0  144.0  150.0  178.0  195.0   \n",
      "18    ...    176.0  166.0  169.0  174.0  174.0  171.0  164.0  167.0  177.0   \n",
      "19    ...    134.0  159.0  178.0  185.0  178.0  159.0  143.0  131.0  121.0   \n",
      "20    ...    134.0  150.0  158.0  154.0  158.0  142.0  137.0  143.0  154.0   \n",
      "21    ...    133.0  133.0  144.0  146.0  133.0  133.0  128.0  131.0  152.0   \n",
      "22    ...    134.0  146.0  151.0  151.0  145.0  130.0  132.0  130.0  134.0   \n",
      "23    ...    127.0  131.0  135.0  131.0  126.0  147.0  162.0  143.0  132.0   \n",
      "24    ...    124.0  135.0  136.0  139.0  135.0  130.0  134.0  157.0  182.0   \n",
      "25    ...    128.0  144.0  153.0  152.0  148.0  142.0  140.0  144.0  150.0   \n",
      "26    ...    128.0  131.0  136.0  131.0  125.0  111.0  135.0  135.0  155.0   \n",
      "27    ...    113.0  137.0  149.0  154.0  160.0  158.0  144.0  136.0  146.0   \n",
      "28    ...     99.0  116.0  140.0  144.0  138.0  132.0  120.0  112.0  115.0   \n",
      "29    ...    161.0  172.0  172.0  174.0  173.0  171.0  174.0  181.0  195.0   \n",
      "...   ...      ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "1106  ...    154.0  160.0  171.0  173.0  156.0  139.0  127.0  125.0  171.0   \n",
      "1107  ...    137.0  152.0  178.0  178.0  175.0  160.0  154.0  146.0  183.0   \n",
      "1108  ...    111.0  142.0  153.0  158.0  157.0  154.0  145.0  141.0  137.0   \n",
      "1109  ...    160.0  164.0  164.0  140.0  128.0  123.0  123.0  144.0  173.0   \n",
      "1110  ...    128.0  129.0  131.0  134.0  136.0  143.0  152.0  158.0  172.0   \n",
      "1111  ...    131.0  134.0  132.0  140.0  140.0  136.0  125.0  130.0  149.0   \n",
      "1112  ...    129.0  131.0  136.0  131.0  119.0  120.0  119.0  126.0  139.0   \n",
      "1113  ...    140.0  142.0  140.0  133.0  128.0  122.0  120.0  126.0  138.0   \n",
      "1114  ...    131.0  148.0  155.0  153.0  146.0  137.0  120.0  116.0  109.0   \n",
      "1115  ...     68.0   73.0   76.0   75.0   86.0  106.0  111.0  105.0   95.0   \n",
      "1116  ...    145.0  162.0  173.0  172.0  158.0  127.0  122.0  119.0  135.0   \n",
      "1117  ...    134.0  165.0  174.0  175.0  163.0  154.0  129.0  132.0  145.0   \n",
      "1118  ...    132.0  161.0  175.0  188.0  186.0  166.0  160.0  163.0  167.0   \n",
      "1119  ...    117.0  136.0  152.0  159.0  154.0  143.0  111.0  107.0  115.0   \n",
      "1120  ...    139.0  156.0  158.0  155.0  149.0  144.0  130.0  131.0  135.0   \n",
      "1121  ...    142.0  147.0  151.0  145.0  146.0  146.0  146.0  144.0  158.0   \n",
      "1122  ...    167.0  175.0  181.0  182.0  179.0  174.0  162.0  158.0  164.0   \n",
      "1123  ...    104.0  125.0  141.0  147.0  142.0  139.0  121.0  127.0  136.0   \n",
      "1124  ...    143.0  157.0  158.0  154.0  148.0  140.0  129.0  127.0  130.0   \n",
      "1125  ...    123.0  150.0  164.0  170.0  168.0  161.0  149.0  134.0  134.0   \n",
      "1126  ...    138.0  148.0  148.0  134.0  138.0  135.0  127.0  143.0  166.0   \n",
      "1127  ...    118.0  150.0  150.0  149.0  143.0  136.0  131.0  136.0  151.0   \n",
      "1128  ...    140.0  166.0  166.0  156.0  150.0  135.0  136.0  152.0  172.0   \n",
      "1129  ...    144.0  155.0  157.0  156.0  143.0  130.0  126.0  116.0  126.0   \n",
      "1130  ...    140.0  142.0  143.0  141.0  136.0  120.0  115.0  117.0  139.0   \n",
      "1131  ...    146.0  166.0  177.0  174.0  166.0  157.0  154.0  161.0  170.0   \n",
      "1132  ...    163.0  164.0  167.0  166.0  157.0  138.0  142.0  152.0  190.0   \n",
      "1133  ...    154.0  166.0  174.0  177.0  167.0  153.0  145.0  150.0  165.0   \n",
      "1134  ...    180.0  180.0  181.0  172.0  169.0  157.0  157.0  161.0  175.0   \n",
      "1135  ...    162.0  168.0  170.0  170.0  164.0  160.0  153.0  158.0  181.0   \n",
      "\n",
      "       f101  \n",
      "0     195.0  \n",
      "1     221.0  \n",
      "2     191.0  \n",
      "3     163.0  \n",
      "4     231.0  \n",
      "5     143.0  \n",
      "6     215.0  \n",
      "7     176.0  \n",
      "8     152.0  \n",
      "9     135.0  \n",
      "10    166.0  \n",
      "11    159.0  \n",
      "12    159.0  \n",
      "13    135.0  \n",
      "14    163.0  \n",
      "15    173.0  \n",
      "16    162.0  \n",
      "17    215.0  \n",
      "18    192.0  \n",
      "19    125.0  \n",
      "20    165.0  \n",
      "21    179.0  \n",
      "22    155.0  \n",
      "23    150.0  \n",
      "24    196.0  \n",
      "25    170.0  \n",
      "26    188.0  \n",
      "27    154.0  \n",
      "28    128.0  \n",
      "29    206.0  \n",
      "...     ...  \n",
      "1106  215.0  \n",
      "1107  217.0  \n",
      "1108  147.0  \n",
      "1109  192.0  \n",
      "1110  188.0  \n",
      "1111  176.0  \n",
      "1112  166.0  \n",
      "1113  167.0  \n",
      "1114  125.0  \n",
      "1115   95.0  \n",
      "1116  201.0  \n",
      "1117  189.0  \n",
      "1118  177.0  \n",
      "1119  144.0  \n",
      "1120  144.0  \n",
      "1121  177.0  \n",
      "1122  175.0  \n",
      "1123  166.0  \n",
      "1124  159.0  \n",
      "1125  136.0  \n",
      "1126  172.0  \n",
      "1127  182.0  \n",
      "1128  200.0  \n",
      "1129  150.0  \n",
      "1130  135.0  \n",
      "1131  203.0  \n",
      "1132  212.0  \n",
      "1133  181.0  \n",
      "1134  188.0  \n",
      "1135  228.0  \n",
      "\n",
      "[1136 rows x 102 columns]\n",
      "(1134, 102)\n",
      "(1134, 102)\n"
     ]
    }
   ],
   "source": [
    "clase = read_csv_files('clases/')\n",
    "\n",
    "print(clase[0])\n",
    "\n",
    "\n",
    "print(clase[1].shape)\n",
    "print(clase[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Genero el dataset que usaré para los experimentos. Para este ejemplo, voy a usar los cromosomas de la clase 1 y 2 solamente. Se podría extender para usar más cromosomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clases_a_usar = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for idx in clases_a_usar:\n",
    "    \n",
    "    x = np.array(clase[idx]).tolist()\n",
    "    y = idx * np.ones((clase[idx].shape[0]))\n",
    "    y = y.tolist()\n",
    "    \n",
    "    X.extend(x)\n",
    "    Y.extend(y)\n",
    "\n",
    "#print(X[0])\n",
    "#print(X[-1])\n",
    "#print(Y[0])\n",
    "#print(Y[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTA**: Es má fácil manipular listas de número en lugar de arreglos numpy. Scikit-learn acepta tanto arreglos de numpy como listas de python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Particionado de los datos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "TRAIN DATA\n",
      "[ 20.  13.   3. ...,   8.   9.   2.]\n",
      "-----------\n",
      "TEST DATA\n",
      "[ 20.  20.  13. ...,   0.  13.  15.]\n"
     ]
    }
   ],
   "source": [
    "# TRAIN: 80% -- TEST: 20%\n",
    "#X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X,Y,test_size=0.4,random_state=0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "\n",
    "# Ahora si convierto a NUMPY\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "\n",
    "print('-----------')\n",
    "print('TRAIN DATA')\n",
    "#print(X_train)\n",
    "print(Y_train)\n",
    "\n",
    "print('-----------')\n",
    "print('TEST DATA')\n",
    "#print (X_test)\n",
    "print (Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Preprocesamiento</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Estandarización</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.65300000e+03,   6.57900000e+03,   6.66100000e+03,\n",
       "          3.67000000e+03,   1.65100000e+03,   5.98000000e+02,\n",
       "          8.10000000e+01,   3.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([-2.09433569, -1.23663995, -0.37894421,  0.47875152,  1.33644726,\n",
       "         2.19414299,  3.05183873,  3.90953446,  4.7672302 ,  5.62492594,\n",
       "         6.48262167]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD9CAYAAABazssqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktSx/w8wGGQEZzFy5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd982a2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)                    # Built scaler to normalize values (mean=0.0 and std=1.0)\n",
    "#scaler = preprocessing.MinMaxScaler(feature_range=(0,1)).fit(X_train)  # Built scaler to scale values in range [Xmin,Xmax]\n",
    "#scaler = preprocessing.MaxAbsScaler().fit(X_train)                     # Built scaler to scale values in range [-1,1]\n",
    "\n",
    "# APPLY TRAINED SCALER\n",
    "sX_train = scaler.transform(X_train)\n",
    "\n",
    "sX_test = scaler.transform(X_test)\n",
    "\n",
    "sX_train.mean(axis=0)\n",
    "#sX_train.std(axis=0)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(np.array(X_train)[:,1],color='b')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(np.array(sX_train)[:,1],color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Normalización de los datos</h2>\n",
    "\n",
    "Revisar: *http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.65300000e+03,   6.57900000e+03,   6.88700000e+03,\n",
       "          3.44400000e+03,   1.69800000e+03,   5.51000000e+02,\n",
       "          8.10000000e+01,   3.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([ 0.00040351,  0.00282459,  0.00524566,  0.00766674,  0.01008781,\n",
       "         0.01250889,  0.01492997,  0.01735104,  0.01977212,  0.02219319,\n",
       "         0.02461427]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD9CAYAAABazssqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgIiIhGmJCAiEmH/H3ac+Kh2i1oeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd983be438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Previamente estandarizado (cada patrón tiene media=0 y varianza=1)\n",
    "normalizer = preprocessing.Normalizer(norm='l2', copy=True).fit(X_train.T)\n",
    "\n",
    "nX_train = normalizer.transform(X_train.T)\n",
    "nX_test = normalizer.transform(X_test.T)\n",
    "\n",
    "# Traspongo nuevamente\n",
    "nX_train = nX_train.T\n",
    "nX_test = nX_test.T\n",
    "\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(np.array(X_train)[:,1],color='b')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(np.array(sX_train)[:,1],color='r')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(np.array(nX_train)[:,1],color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Construcción del clasificador</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', gamma='auto', C=1, cache_size=500)\n",
    "#clf = svm.SVC(kernel='rbf', gamma=0.1, C=1000, cache_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Entrenamiento del clasificador</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=500, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAIN = X_train  # --> Datos CRUDOS\n",
    "TRAIN = sX_train # --> Datos ESTANDARIZADOS\n",
    "#TRAIN = nX_train # --> Datos NORMALIZADOS\n",
    "\n",
    "clf.fit(TRAIN, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2>Predicción y medidas de desempeño</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.87\n",
      "\n",
      "CONFUSSION MATRIX\n",
      "[[214   3   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  3 221   2   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1   0]\n",
      " [  1   1 204   0   1   9   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  1   3   4 181   9   3   1   0   1   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   2   0]\n",
      " [  0   1   5  24 204   2   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   1   0]\n",
      " [  2   2   3   2   0 203   3   2   2   3   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   1   0]\n",
      " [  2   1   1   0   1   2 208   3   4   1   0   3   1   0   0   1   0   0\n",
      "    0   0   0   0   2   0]\n",
      " [  0   1   2   0   0   0   0 208   7   0   2   0   1   4   0   1   0   0\n",
      "    0   0   0   0   3   0]\n",
      " [  0   1   1   0   0   0   4   5 181   3   0   1   1   1   0   2   1   0\n",
      "    1   0   0   0   7   0]\n",
      " [  0   0   0   1   1   1   0   4   3 195   3   0   2   3   3   1   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   2   0   1   2 203   5   1   1   0   0   2   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   1   1   2   1   0   2   6   0   3 214   3   0   0   0   1   0\n",
      "    0   0   0   0   3   0]\n",
      " [  0   0   0   0   0   0   5   6   0   0   1   2 195   3   3   4   0   0\n",
      "    0   0   1   0   1   0]\n",
      " [  0   0   0   0   0   0   1   2   2   3   0   0   5 232  11   3   3   3\n",
      "    0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   1   2   0   0   6   7 204   3   0   2\n",
      "    2   2   0   0   3   0]\n",
      " [  0   0   0   0   0   0   0   0   2   8   0   0  13   3   4 180   3  12\n",
      "    2   4   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   3   2   0   1   4   0   3 190   3\n",
      "    0   7   1   1   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   4   6   9   3 194\n",
      "    2   1   0   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   2   5   2   1   5\n",
      "  187   6   9  24   0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   3   7   2\n",
      "   11 191   3   9   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   0\n",
      "    8   0 203  14   0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   1   0   1\n",
      "   21  11   9 178   0   4]\n",
      " [  0   0   4   3   1   2   1   5  12   1   3   1   0   0   1   1   0   0\n",
      "    0   0   0   0 132   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   1   2\n",
      "    5   2   0   3   0  42]]\n",
      "\n",
      "\n",
      "Classification report for classifier SVC(C=1, cache_size=500, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.98      0.97       218\n",
      "        1.0       0.94      0.96      0.95       230\n",
      "        2.0       0.90      0.94      0.92       217\n",
      "        3.0       0.85      0.88      0.86       206\n",
      "        4.0       0.92      0.86      0.89       238\n",
      "        5.0       0.90      0.91      0.90       224\n",
      "        6.0       0.92      0.90      0.91       230\n",
      "        7.0       0.88      0.91      0.89       229\n",
      "        8.0       0.81      0.87      0.84       209\n",
      "        9.0       0.88      0.89      0.89       218\n",
      "       10.0       0.94      0.93      0.93       218\n",
      "       11.0       0.94      0.90      0.92       237\n",
      "       12.0       0.83      0.88      0.86       221\n",
      "       13.0       0.87      0.87      0.87       266\n",
      "       14.0       0.85      0.88      0.86       232\n",
      "       15.0       0.84      0.78      0.81       232\n",
      "       16.0       0.90      0.86      0.88       220\n",
      "       17.0       0.86      0.87      0.87       223\n",
      "       18.0       0.78      0.77      0.77       244\n",
      "       19.0       0.85      0.83      0.84       231\n",
      "       20.0       0.90      0.88      0.89       230\n",
      "       21.0       0.77      0.78      0.78       228\n",
      "       22.0       0.85      0.79      0.82       167\n",
      "       23.0       0.72      0.74      0.73        57\n",
      "\n",
      "avg / total       0.87      0.87      0.87      5225\n",
      "\n",
      "\n",
      "K fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asusn56/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#TEST = X_test  # --> Datos CRUDOS\n",
    "TEST = sX_test # --> Datos ESTANDARIZADOS\n",
    "#TEST = nX_test # --> Datos NORMALIZADOS\n",
    "\n",
    "#======================\n",
    "# SCORE CALCULATION\n",
    "#======================\n",
    "score = clf.score(TEST, Y_test)\n",
    "\n",
    "print(\"\\nAccuracy: %0.2f\" % (score))\n",
    "\n",
    "\n",
    "\n",
    "#===================\n",
    "# CONFUSSION MATRIX\n",
    "#===================\n",
    "Y_pred = clf.predict(TEST)\n",
    "\n",
    "print('\\nCONFUSSION MATRIX')\n",
    "cm=metrics.confusion_matrix(Y_test,Y_pred)\n",
    "print(cm)\n",
    "\n",
    "#MATRIZ DE CONFUSION\n",
    "\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#=========\n",
    "# REPORT\n",
    "#=========\n",
    "print(\"\\n\\nClassification report for classifier %s:\\n\\n%s\\n\"\n",
    "      %\n",
    "      (clf, metrics.classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante ver que en la diagonal de la matriz de confusión están los valores más altos (se confunde relativamente poco el clasificador)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}